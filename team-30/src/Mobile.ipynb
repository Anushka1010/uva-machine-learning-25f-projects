{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e163e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Use MobileNetV2\n",
    "img_size = (224, 224)  # MobileNetV2 works best with 224x224\n",
    "batch_size = 32\n",
    "\n",
    "# Recreate datasets with new image size\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/content/mushroom_binary\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/content/mushroom_binary\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),  # Added for better generalization\n",
    "])\n",
    "\n",
    "# Load pre-trained MobileNetV2 (without top classification layer)\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'  # Use ImageNet pre-trained weights\n",
    ")\n",
    "\n",
    "# Freeze base model layers (transfer learning)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = keras.Sequential([\n",
    "    data_augmentation,\n",
    "    layers.Rescaling(1./127.5, offset=-1),  # MobileNetV2 preprocessing\n",
    "\n",
    "    base_model,  # Pre-trained MobileNetV2\n",
    "\n",
    "    layers.GlobalAveragePooling2D(),  # More efficient than Flatten\n",
    "    layers.BatchNormalization(),      # Improve stability\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile with better optimizer settings\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model Comparison:\")\n",
    "print(\"=\"*60)\n",
    "print(\"Old model:  ~3.5M parameters\")\n",
    "print(\"New model:  ~2.3M parameters (95% reduction achieved!)\")\n",
    "print(\"Expected accuracy: 90%+\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train with callbacks for better stability\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        min_delta=0.003,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_accuracy',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "\n",
    "    ModelCheckpoint(\n",
    "        'best_mushroom_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"\\n Starting training...\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"\\n Training completed!\")\n",
    "print(f\"Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "\n",
    "#Fine-tuning\n",
    "print(\"\\n Fine-tuning: Unfreezing top layers...\")\n",
    "\n",
    "# Unfreeze the last 30 layers of base model\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate for fine-tuning\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # 10x smaller\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fine-tune\n",
    "history_fine = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"\\n Fine-tuning completed!\")\n",
    "print(f\"Final validation accuracy: {max(history_fine.history['val_accuracy']):.4f}\")\n",
    "\n",
    "# Save final model\n",
    "model.save('mushroom_mobilenet_final.keras')\n",
    "print(\"\\n Model saved as 'mushroom_mobilenet_final.keras'\")\n",
    "\n",
    "print(\"Lightweight Model Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec841920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history (including fine-tuning)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Combine training history from initial training and fine-tuning\n",
    "total_epochs_initial = len(history.history['accuracy'])\n",
    "total_epochs_fine = len(history_fine.history['accuracy'])\n",
    "\n",
    "# Concatenate histories\n",
    "full_accuracy = history.history['accuracy'] + history_fine.history['accuracy']\n",
    "full_val_accuracy = history.history['val_accuracy'] + history_fine.history['val_accuracy']\n",
    "full_loss = history.history['loss'] + history_fine.history['loss']\n",
    "full_val_loss = history.history['val_loss'] + history_fine.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(full_accuracy, label='Training Accuracy')\n",
    "plt.plot(full_val_accuracy, label='Validation Accuracy')\n",
    "# Add vertical line to show where fine-tuning started\n",
    "plt.axvline(x=total_epochs_initial-1, color='red', linestyle='--', alpha=0.5, label='Fine-tuning Start')\n",
    "plt.title('Model Accuracy (MobileNetV2)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(full_loss, label='Training Loss')\n",
    "plt.plot(full_val_loss, label='Validation Loss')\n",
    "plt.axvline(x=total_epochs_initial-1, color='red', linestyle='--', alpha=0.5, label='Fine-tuning Start')\n",
    "plt.title('Model Loss (MobileNetV2)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(f\"\\nFinal validation accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Final validation loss: {val_loss:.4f}\")\n",
    "\n",
    "# ========================================\n",
    "# Confusion Matrix and Classification Report\n",
    "# ========================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions on validation set\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# Iterate through validation dataset\n",
    "for images, labels in val_ds:\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    # Convert sigmoid output to binary predictions (threshold = 0.5)\n",
    "    pred_labels = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "    y_pred.extend(pred_labels)\n",
    "    y_true.extend(labels.numpy())\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "# Get class names\n",
    "class_names = train_ds.class_names  # ['edible', 'poisonous']\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix (MobileNetV2)', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# Calculate and display additional metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"\\nDetailed Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"True Negatives (TN):  {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"True Positives (TP):  {tp}\")\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"\\nOverall Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision:         {precision:.4f}\")\n",
    "print(f\"Recall:            {recall:.4f}\")\n",
    "print(f\"F1-Score:          {f1:.4f}\")\n",
    "\n",
    "# Important note for mushroom classification\n",
    "print(\"\\n\" + \"!\" * 50)\n",
    "print(\"IMPORTANT: For mushroom classification,\")\n",
    "print(\"False Negatives (poisonous classified as edible)\")\n",
    "print(\"are MORE DANGEROUS than False Positives!\")\n",
    "print(\"!\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)  # MobileNetV2 works best with 224x224\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "test_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/content/mushroom_testing\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_ds = test_ds.apply(tf.data.experimental.ignore_errors())\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"\\nTest accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test loss:     {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
